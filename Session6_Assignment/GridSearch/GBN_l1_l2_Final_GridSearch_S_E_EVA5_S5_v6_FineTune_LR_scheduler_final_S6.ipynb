{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GBN_l1_l2_Final_GridSearch_S_E_EVA5_S5_v6_FineTune_LR_scheduler_final_S6.ipynb","provenance":[{"file_id":"1YcGBgcg8jZhvZnnRHh-e1RtJ75vI35Xp","timestamp":1598601292359},{"file_id":"1657lPmGc19o8V962MGS2gxHHyRH2UqvY","timestamp":1598530815782},{"file_id":"1S4x7aKoMf3FOcZjsvIOok7Kgebl1N6RQ","timestamp":1598502194415},{"file_id":"1OHGqLyD3drzJsEQZoKSzEWRi-iVFqU3x","timestamp":1598425777205},{"file_id":"11aO5MvPbTIH8XhaVGwT_Xyer_hNtCUQO","timestamp":1598378480510},{"file_id":"1dfMT9YubdT_ZyBEKRQlntPLCYW64cMj0","timestamp":1597953574625},{"file_id":"1iB6PmFLHbR97kKY_hQOCQ8hNKQIAxTaz","timestamp":1597950458466},{"file_id":"1EPKHLE64sTorpo_Lg_npxfZohd7RqMGB","timestamp":1597949817775},{"file_id":"1_EgbhPf92U_W8S7UzC38hxggS30Vq-BA","timestamp":1597949411678},{"file_id":"1yDfE0pIWjGkB51NqzhgYMW5dxh13R1Hc","timestamp":1597948798432},{"file_id":"1y3CmvuCn2PyWGtiALyHXJhlvPCc1gbKg","timestamp":1597948004452},{"file_id":"1zx12oDfnadaVjEwQfUtAwfCQTSqZxRwj","timestamp":1597946538285},{"file_id":"1aFgWmHNJoCyZ56zRvoE8xUdAe285aWmb","timestamp":1581394625836}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0183ee89ac4e4a0eb0d3b1b1a2bdf2f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b7efaff41ced42fc8cab2a5a79418424","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_dd5c535c99f646c3aac35dcd4a174271","IPY_MODEL_533b1098711f48dc95e99639672a2fbd"]}},"b7efaff41ced42fc8cab2a5a79418424":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dd5c535c99f646c3aac35dcd4a174271":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_58e513af9efe42ed86c83077e4ebf706","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5347f355405146fcb2ddbe69ced2fbea"}},"533b1098711f48dc95e99639672a2fbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d100783f36f4eef867ffadb4efadb67","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9920512/? [00:20&lt;00:00, 1279446.43it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f8f2c78593ba47e09010a5e1f40dcf0d"}},"58e513af9efe42ed86c83077e4ebf706":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5347f355405146fcb2ddbe69ced2fbea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3d100783f36f4eef867ffadb4efadb67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f8f2c78593ba47e09010a5e1f40dcf0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b3e62f98560d437a982b7109933bb351":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f3e7641261b14dcfb942db982c47833b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_83309ecf3be5449f958a1863f19f806f","IPY_MODEL_71a4b3a78e024f4bb46863cb70bc2eee"]}},"f3e7641261b14dcfb942db982c47833b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83309ecf3be5449f958a1863f19f806f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_16826be2274840adb9fc523596ecab86","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0ed376c5898f4f42a3b508c75e1a3e19"}},"71a4b3a78e024f4bb46863cb70bc2eee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d5fae739ac4745cabf857c04f5cb2bbb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 32768/? [00:05&lt;00:00, 6188.75it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_abe05e23c5214e0d952fc2d68ff277f0"}},"16826be2274840adb9fc523596ecab86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0ed376c5898f4f42a3b508c75e1a3e19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5fae739ac4745cabf857c04f5cb2bbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"abe05e23c5214e0d952fc2d68ff277f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22e4edc1aac64fbd9126614d26ec286d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bef4ffc5b35a4720994f8970c9d6eda7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_54c52025f7d14fb0ac5202cf7c6ca972","IPY_MODEL_e72dbc0e0ec04a25894d0bc908b4719b"]}},"bef4ffc5b35a4720994f8970c9d6eda7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"54c52025f7d14fb0ac5202cf7c6ca972":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a908354c39a247b7af875c5d7be3df47","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_26bcdc0008da44e0b0195163465c2352"}},"e72dbc0e0ec04a25894d0bc908b4719b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4a3474957f4542b7a60fd9d7e88cfc35","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1654784/? [00:04&lt;00:00, 373414.59it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f971984e50bb40a386162b7c91469145"}},"a908354c39a247b7af875c5d7be3df47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"26bcdc0008da44e0b0195163465c2352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4a3474957f4542b7a60fd9d7e88cfc35":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f971984e50bb40a386162b7c91469145":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ed8598725cf7470c8ddd179ee43e8b0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b2296532ff3649fab41c9745878e08d7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fd2f959211aa476180d09427249ebce6","IPY_MODEL_5cd72506fab84cb18e3a86050d65deab"]}},"b2296532ff3649fab41c9745878e08d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd2f959211aa476180d09427249ebce6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_02cca96d7a3d424697680484b21acabc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9de41014901e4e58a3022e5252e7f34d"}},"5cd72506fab84cb18e3a86050d65deab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_205aa00b0ea4488ea62f7cc5db51b014","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 8192/? [00:02&lt;00:00, 3274.16it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4607038b32bb4f9d9fafe0ab5938b516"}},"02cca96d7a3d424697680484b21acabc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9de41014901e4e58a3022e5252e7f34d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"205aa00b0ea4488ea62f7cc5db51b014":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4607038b32bb4f9d9fafe0ab5938b516":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"0MWDgf5dUEFk","colab_type":"text"},"source":["# FineTune_LR_scheduler - S5_v6"]},{"cell_type":"markdown","metadata":{"id":"1zyfvtCFICOU","colab_type":"text"},"source":["\n","# Target:\n","\n","1. FineTune LR scheduler. Set LR=0.1 as before but updated StepSize = 12 and Gamma = 0.2\n","\n","# Results:\n","\n","1. Parameters: 7,612\n","2. Best Train Accuracy: 99.41\n","3. Best Test Accuracy: 99.49\n","\n","# Analysis:\n","1. To get best combination values StepSize = 12 and Gamma =0.2, we tried many trails of these two values.\n","2. The intuition behind above values is, we observed the accuracy is gradually increasing till around 10 epochs and getting stall from there. So we would like to update LR around 10-12 epochs.\n","3. We tried with StepSize and Gamma combinations - (10, 0.1), (11, 0.1), (12, 0.1) But didn't help to get the target accuracy consistently at last few epochs.\n","4. So we thought to increase the speed a little bit after 10-12 epochs by updating gamma = 0.2 and tried these StepSize and Gamma combinations - (10, 0.2), (11, 0.2), (12, 0.2) And finaally Stepsize=12, Gamma=0.2 gave best consistency of >=99.4% in the last 3 epochs and hit maximum of 99.49% with less than 8000 parameters\n"]},{"cell_type":"markdown","metadata":{"id":"aO-7t1Y7-hV4","colab_type":"text"},"source":["# Import Libraries"]},{"cell_type":"code","metadata":{"id":"8kH16rnZ7wt_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602239808,"user_tz":-330,"elapsed":4883,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.optim.lr_scheduler import StepLR\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import time "],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"FkgEpHeg6fOH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1598602306073,"user_tz":-330,"elapsed":71122,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}},"outputId":"708f72d3-65cf-427e-f7eb-aa207ee1776e"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G77NEAIK3PaV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602306077,"user_tz":-330,"elapsed":71122,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["import logging\n","  \n","logger = logging.getLogger(\"\")\n","#logging.basicConfig(level=logging.DEBUG)\n","filename = '/content/drive/My Drive/GBN_l1_l2_Final_GridSearch_S_E_EVA5_S5_v6_FineTune_LR_scheduler_final_S6_'+time.ctime().replace(' ','_')+'.txt'\n","logging.basicConfig(level = logging.DEBUG, filename = filename)\n","# logger.debug('Loging %s lewel', 'DEBUG')\n","# logger.info('Loging %s lewel', 'INFO')\n","# logger.warning('Loging %s lewel', 'WARN')\n","# logger.error('Loging %s lewel', 'ERROR')\n","# logger.critical('Loging %s lewel', 'CRITICAL')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmcHYOj6hKpj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598602306081,"user_tz":-330,"elapsed":71117,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}},"outputId":"f8a60a9a-d72f-4854-a22c-513372bb59c1"},"source":["time.ctime()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Fri Aug 28 08:11:43 2020'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"7RlReRL6mDLk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598602306083,"user_tz":-330,"elapsed":71111,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}},"outputId":"ab9ab0c6-6f7c-4f04-c003-b59afeb95ff6"},"source":["time.ctime().replace(' ','_')"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Fri_Aug_28_08:11:43_2020'"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ky3f_Odl-7um","colab_type":"text"},"source":["## Data Transformations\n","\n","We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n"]},{"cell_type":"code","metadata":{"id":"YtssFUKb-jqx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602306085,"user_tz":-330,"elapsed":71110,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["train_transforms = transforms.Compose([\n","    transforms.RandomRotation((-7.0, 7.0), fill=(1,)),                                   \n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])\n","\n","test_transforms = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oQciFYo2B1mO","colab_type":"text"},"source":["# Dataset and Creating Train/Test Split"]},{"cell_type":"code","metadata":{"id":"_4A84rlfDA23","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":373,"referenced_widgets":["0183ee89ac4e4a0eb0d3b1b1a2bdf2f7","b7efaff41ced42fc8cab2a5a79418424","dd5c535c99f646c3aac35dcd4a174271","533b1098711f48dc95e99639672a2fbd","58e513af9efe42ed86c83077e4ebf706","5347f355405146fcb2ddbe69ced2fbea","3d100783f36f4eef867ffadb4efadb67","f8f2c78593ba47e09010a5e1f40dcf0d","b3e62f98560d437a982b7109933bb351","f3e7641261b14dcfb942db982c47833b","83309ecf3be5449f958a1863f19f806f","71a4b3a78e024f4bb46863cb70bc2eee","16826be2274840adb9fc523596ecab86","0ed376c5898f4f42a3b508c75e1a3e19","d5fae739ac4745cabf857c04f5cb2bbb","abe05e23c5214e0d952fc2d68ff277f0","22e4edc1aac64fbd9126614d26ec286d","bef4ffc5b35a4720994f8970c9d6eda7","54c52025f7d14fb0ac5202cf7c6ca972","e72dbc0e0ec04a25894d0bc908b4719b","a908354c39a247b7af875c5d7be3df47","26bcdc0008da44e0b0195163465c2352","4a3474957f4542b7a60fd9d7e88cfc35","f971984e50bb40a386162b7c91469145","ed8598725cf7470c8ddd179ee43e8b0b","b2296532ff3649fab41c9745878e08d7","fd2f959211aa476180d09427249ebce6","5cd72506fab84cb18e3a86050d65deab","02cca96d7a3d424697680484b21acabc","9de41014901e4e58a3022e5252e7f34d","205aa00b0ea4488ea62f7cc5db51b014","4607038b32bb4f9d9fafe0ab5938b516"]},"executionInfo":{"status":"ok","timestamp":1598602314688,"user_tz":-330,"elapsed":79708,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}},"outputId":"677736c5-464e-47cf-93ed-e0e36e687d55"},"source":["train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n","test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0183ee89ac4e4a0eb0d3b1b1a2bdf2f7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b3e62f98560d437a982b7109933bb351","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22e4edc1aac64fbd9126614d26ec286d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed8598725cf7470c8ddd179ee43e8b0b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qgldp_3-Dn0c","colab_type":"text"},"source":["# Dataloader Arguments & Test/Train Dataloaders\n"]},{"cell_type":"code","metadata":{"id":"C8OLDR79DrHG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1598602314690,"user_tz":-330,"elapsed":79707,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}},"outputId":"2e7f2ac6-f4a0-4c7c-dd53-70df90d2788b"},"source":["SEED = 1\n","\n","# CUDA?\n","cuda = torch.cuda.is_available()\n","# logger.info(\"CUDA Available?\", cuda)\n","# logger.info(f\"CUDA Available? {cuda}\")\n","\n","# For reproducibility\n","torch.manual_seed(SEED)\n","\n","if cuda:\n","    torch.cuda.manual_seed(SEED)\n","\n","# dataloader arguments - something you'll fetch these from cmdprmt\n","dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n","\n","# train dataloader\n","train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n","\n","# test dataloader\n","test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ubQL3H6RJL3h","colab_type":"text"},"source":["# The model\n","Let's start with the model we first saw"]},{"cell_type":"code","metadata":{"id":"Ts6A8MUHg5sA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602314691,"user_tz":-330,"elapsed":79704,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["class BatchNorm(nn.BatchNorm2d):\n","    def __init__(self, num_features, eps=1e-05, momentum=0.1, weight=True, bias=True):\n","        super().__init__(num_features, eps=eps, momentum=momentum)\n","        self.weight.data.fill_(1.0)\n","        self.bias.data.fill_(0.0)\n","        self.weight.requires_grad = weight\n","        self.bias.requires_grad = bias\n","\n","\n","class GhostBatchNorm(BatchNorm):\n","    def __init__(self, num_features, num_splits, **kw):\n","        super().__init__(num_features, **kw)\n","        self.num_splits = num_splits\n","        self.register_buffer('running_mean', torch.zeros(num_features * self.num_splits))\n","        self.register_buffer('running_var', torch.ones(num_features * self.num_splits))\n","\n","    def train(self, mode=True):\n","        if (self.training is True) and (mode is False):  # lazily collate stats when we are going to use them\n","            self.running_mean = torch.mean(self.running_mean.view(self.num_splits, self.num_features), dim=0).repeat(\n","                self.num_splits)\n","            self.running_var = torch.mean(self.running_var.view(self.num_splits, self.num_features), dim=0).repeat(\n","                self.num_splits)\n","        return super().train(mode)\n","\n","    def forward(self, input):\n","        N, C, H, W = input.shape\n","        if self.training or not self.track_running_stats:\n","            return F.batch_norm(\n","                input.view(-1, C * self.num_splits, H, W), self.running_mean, self.running_var,\n","                self.weight.repeat(self.num_splits), self.bias.repeat(self.num_splits),\n","                True, self.momentum, self.eps).view(N, C, H, W)\n","        else:\n","            return F.batch_norm(\n","                input, self.running_mean[:self.num_features], self.running_var[:self.num_features],\n","                self.weight, self.bias, False, self.momentum, self.eps)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"7FXQlB9kH1ov","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602314695,"user_tz":-330,"elapsed":79705,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["num_splits = 2\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            GhostBatchNorm(num_features=8, num_splits=num_splits)\n","        ) # output_size = 26\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            GhostBatchNorm(num_features=16, num_splits=num_splits)\n","        ) # output_size = 24\n","\n","        # TRANSITION BLOCK 1\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 12\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=8, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.ReLU(),\n","            GhostBatchNorm(num_features=8, num_splits=num_splits)\n","        ) # output_size = 12\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            GhostBatchNorm(num_features=16, num_splits=num_splits)\n","        ) # output_size = 10\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            GhostBatchNorm(num_features=32, num_splits=num_splits)\n","        ) # output_size = 8\n","\n","        # OUTPUT BLOCK\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.ReLU(),\n","            GhostBatchNorm(num_features=10, num_splits=num_splits)\n","        ) # output_size = 8\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=8)\n","        ) # output_size = 1\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.pool1(x)\n","        x = self.convblock3(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        x = self.gap(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M3-vp8X9LCWo","colab_type":"text"},"source":["# Model Params\n","Can't emphasize on how important viewing Model Summary is. \n","Unfortunately, there is no in-built model visualizer, so we have to take external help"]},{"cell_type":"code","metadata":{"id":"5skB97zIJQQe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":607},"executionInfo":{"status":"ok","timestamp":1598602328720,"user_tz":-330,"elapsed":93721,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}},"outputId":"55564d0f-3004-42e8-a434-5a87fbaba4fb"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","# logger.info(device)\n","logger.info(f\"Device : {device}\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 26, 26]              72\n","              ReLU-2            [-1, 8, 26, 26]               0\n","    GhostBatchNorm-3            [-1, 8, 26, 26]              16\n","            Conv2d-4           [-1, 16, 24, 24]           1,152\n","              ReLU-5           [-1, 16, 24, 24]               0\n","    GhostBatchNorm-6           [-1, 16, 24, 24]              32\n","         MaxPool2d-7           [-1, 16, 12, 12]               0\n","            Conv2d-8            [-1, 8, 12, 12]             128\n","              ReLU-9            [-1, 8, 12, 12]               0\n","   GhostBatchNorm-10            [-1, 8, 12, 12]              16\n","           Conv2d-11           [-1, 16, 10, 10]           1,152\n","             ReLU-12           [-1, 16, 10, 10]               0\n","   GhostBatchNorm-13           [-1, 16, 10, 10]              32\n","           Conv2d-14             [-1, 32, 8, 8]           4,608\n","             ReLU-15             [-1, 32, 8, 8]               0\n","   GhostBatchNorm-16             [-1, 32, 8, 8]              64\n","           Conv2d-17             [-1, 10, 8, 8]             320\n","             ReLU-18             [-1, 10, 8, 8]               0\n","   GhostBatchNorm-19             [-1, 10, 8, 8]              20\n","        AvgPool2d-20             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 7,612\n","Trainable params: 7,612\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.48\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.51\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fT_FHOFBami1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328722,"user_tz":-330,"elapsed":93721,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["# for i in model.parameters():\n","#   logger.info(i)\n","#   break"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1__x_SbrL7z3","colab_type":"text"},"source":["# Training and Testing\n","\n","Looking at logs can be boring, so we'll introduce **tqdm** progressbar to get cooler logs. \n","\n","Let's write train and test functions"]},{"cell_type":"code","metadata":{"id":"lV8c9I01L9M_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328724,"user_tz":-330,"elapsed":93720,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["def get_current_train_acc(model, train_loader):\n","  model.eval()\n","  train_loss = 0\n","  correct = 0\n","  with torch.no_grad():\n","      for data, target in train_loader:\n","          data, target = data.to(device), target.to(device)\n","          output = model(data)\n","          train_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","          pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","          correct += pred.eq(target.view_as(pred)).sum().item()\n","  train_loss /= len(train_loader.dataset)\n","\n","  logger.info('\\nTrain set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","      train_loss, correct, len(train_loader.dataset),\n","      100. * correct / len(train_loader.dataset)))\n","  \n","  train_acc = 100. * correct / len(train_loader.dataset)\n","  return train_acc, train_loss"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"fbkF2nN_LYIb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328725,"user_tz":-330,"elapsed":93719,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["from tqdm import tqdm\n","\n","# train_losses = []\n","# test_losses = []\n","# train_acc = []\n","# test_acc = []\n","\n","def train(model, device, train_loader, optimizer, lambda_l1=0, train_acc=[], train_losses=[]):\n","  model.train()\n","  pbar = tqdm(train_loader)\n","  correct = 0\n","  processed = 0\n","  for batch_idx, (data, target) in enumerate(pbar):\n","    # get samples\n","    data, target = data.to(device), target.to(device)\n","\n","    # Init\n","    optimizer.zero_grad()\n","    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n","    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n","\n","    # Predict\n","    y_pred = model(data)\n","\n","    # Calculate loss\n","    loss = F.nll_loss(y_pred, target)\n","    #train_losses.append(loss)\n","\n","    # L1 regularisation\n","\n","    l1 = 0\n","    for p in model.parameters():\n","      l1 += p.abs().sum()\n","    loss += lambda_l1 * l1\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Update pbar-tqdm\n","    \n","    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","    correct += pred.eq(target.view_as(pred)).sum().item()\n","    processed += len(data)\n","\n","    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Current_train_batch_accuracy={100*correct/processed:0.2f}')\n","  current_train_acc, current_train_loss = get_current_train_acc(model, train_loader)\n","  train_acc.append(current_train_acc)\n","  train_losses.append(current_train_loss)\n","  return train_acc, train_losses\n","\n","def test(model, device, test_loader, test_acc=[], test_losses=[]):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_losses.append(test_loss)\n","\n","    logger.info('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    \n","    test_acc.append(100. * correct / len(test_loader.dataset))\n","    return test_acc, test_losses\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"drokW8wWODKq","colab_type":"text"},"source":["# Let's Train and test our model"]},{"cell_type":"code","metadata":{"id":"P23-o-NBFa0E","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328727,"user_tz":-330,"elapsed":93717,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["# def save_best_model(epochs, model, device, train_loader, optimizer, lambda_l1=0.0, scheduler):\n","#   for epoch in range(EPOCHS):\n","#     logger.info(f\" ***** EPOCH:{epoch} ***** \")\n","#     train(model, device, train_loader, optimizer, epoch, lambda_l1)\n","#     scheduler.step()\n","#     test(model, device, test_loader)\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"8p4iyxo0IdK4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328729,"user_tz":-330,"elapsed":93716,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["def get_best_train_test_acc(train_acc=[], test_acc=[]):\n","  \"\"\"\n","  Example:\n","  train_acc_1=[96.5,98.7,99.2,99.3];test_acc_1=[97.2,98.5, 99.25, 99.2]\n","  assert get_best_train_test_acc(train_acc_1, test_acc_1)==(99.2, 99.25)\n","  \"\"\"\n","  tr_te_acc_pairs = list(zip(train_acc, test_acc))\n","  tr_te_acc_pairs_original = tr_te_acc_pairs[:]\n","  tr_te_acc_pairs.sort(key = lambda x: x[1], reverse=True)\n","  for tr_acc, te_acc in tr_te_acc_pairs:\n","    if tr_acc > te_acc and tr_acc - te_acc >= 1:\n","      tr_te_acc_pairs.remove((tr_acc, te_acc))\n","  return tr_te_acc_pairs[0], tr_te_acc_pairs_original.index(tr_te_acc_pairs[0])+1\n"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMo6bSgKYFJS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328730,"user_tz":-330,"elapsed":93715,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["def save_model(model, PATH='./test_model.pickle'):\n","  \"\"\"\n","   Save trained model at given PATH\n","  \"\"\"\n","  torch.save(model.state_dict(), PATH)\n","  logger.info(f\"Model saved at {PATH}\")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"iewpQKUSUUb-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328732,"user_tz":-330,"elapsed":93714,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["train_acc_1=[96.5,98.7,99.2,99.3];test_acc_1=[97.2,98.5, 99.25, 99.2]\n","get_best_train_test_acc(train_acc_1, test_acc_1)\n","\n","assert get_best_train_test_acc(train_acc_1, test_acc_1)==((99.2, 99.25),3)\n"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"FwZLjJpdcjv2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328733,"user_tz":-330,"elapsed":93711,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["def fit_model(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1, scheduler):\n","  train_acc = []\n","  train_losses = []\n","  test_acc = []\n","  test_losses = []\n","  for epoch in range(EPOCHS):\n","    logger.info(f\"[EPOCH:{epoch}]\")\n","    train_acc, train_losses = train(model, device, train_loader, optimizer, lambda_l1, train_acc, train_losses)\n","    scheduler.step()\n","    test_acc, test_losses = test(model, device, test_loader, test_acc, test_losses)\n","  return train_acc, train_losses, test_acc, test_losses\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"mE7n4kFFydW1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328734,"user_tz":-330,"elapsed":93710,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["      # train_acc, train_losses, test_acc, test_losses = fit_model(epochs, model, device, train_loader, test_loader, optimizer, para, scheduler)\n","      # (best_train_acc, best_test_acc), epoch = get_best_train_test_acc(train_acc, test_acc)\n","      # logger.info(f\"For L1 lambda parameter {para} Best train Accuracy {best_train_acc}% and Best Test Accuracy {best_test_acc}% at Epoch {epoch}\")\n","      # all_lambdal1_train_test_acc_from_best_epoch.append((best_train_acc, best_test_acc, para))\n","      # temp_best_train_acc_list.append(best_train_acc)\n","      # temp_best_test_acc_list.append(best_test_acc)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljNM8Om6vqjo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328735,"user_tz":-330,"elapsed":93708,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["def best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=0, lambda_l2=0, scheduler=None):\n","  temp_best_train_acc_list = []\n","  temp_best_test_acc_list = []\n","  all_lambdal1_train_test_acc_from_best_epoch =[]\n","  train_acc, train_losses, test_acc, test_losses = fit_model(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=lambda_l1, scheduler=scheduler)\n","  (best_train_acc, best_test_acc), epoch = get_best_train_test_acc(train_acc, test_acc)\n","  logger.info(f\"\\n===================> For L1 lambda parameter {lambda_l1}, For L2 lambda parameter {lambda_l2}, Best train Accuracy {best_train_acc}% and Best Test Accuracy {best_test_acc}% at Epoch {epoch} <===================\\n\")\n","  all_lambdal1_train_test_acc_from_best_epoch.append((best_train_acc, best_test_acc, lambda_l1, lambda_l2 ))\n","  temp_best_train_acc_list.append(best_train_acc)\n","  temp_best_test_acc_list.append(best_test_acc)\n","  return temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"9FViXBzUdwDl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598602328736,"user_tz":-330,"elapsed":93706,"user":{"displayName":"naga pavankumar kalepu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgyEBiz_-v88kOZHew5XXK9Wy_BbsB0w0O1YiddVA=s64","userId":"14463626350540278797"}}},"source":["def my_grid_search(epochs, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = [], lambda_l2_range = [], size = 20, l1_l2_trails=0):\n","  best_lambdal1_train_acc = 0.0\n","  best_lambdal1_test_acc = 0.0\n","  best_lambdal1 = 0.0\n","  all_lambdal1_train_test_acc_from_best_epoch = []\n"," \n","\n","  if lambda_l1_range and lambda_l2_range:\n","    if lambda_l1_range[0]>lambda_l1_range[1] or lambda_l2_range[0]>lambda_l2_range[1]:\n","      raise Exception(\"It should be => min<max\")\n","    options_l1 = np.random.uniform(low=lambda_l1_range[0], high=lambda_l1_range[1], size=size)\n","    options_l2 = np.random.uniform(low=lambda_l2_range[0], high=lambda_l2_range[1], size=size)\n","    for i in range(l1_l2_trails):\n","      l1_value = random.choice(options_l1)\n","      l2_value = random.choice(options_l2)\n","      logger.info(f\"\\n L1&L2 Trail:{i+1} - Model is getting trained with L1 regularisation parameter {l1_value} and L2 regularisation parameter {l2_value}\\n\")\n","      model =  Net().to(device)\n","      optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=l2_value)\n","      scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n","      temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch = best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=l1_value, lambda_l2=l2_value, scheduler=scheduler)\n","    \n","    (best_para_train_acc, best_para_test_acc), idx = get_best_train_test_acc(temp_best_train_acc_list, temp_best_test_acc_list)\n","    idx -= 1\n","    final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = all_lambdal1_train_test_acc_from_best_epoch[idx]\n","    logger.info(f\"\\n===================> final_best_train_acc: {final_best_train_acc}, final_best_test_acc: {final_best_test_acc}, final_best_lambda_l1: {final_best_lambda_l1} , final_best_lambda_l2: {final_best_lambda_l2} <===================\\n\")\n","    return final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2\n","\n","\n","  elif lambda_l1_range:\n","    if lambda_l1_range[0]>lambda_l1_range[1]:\n","      raise Exception(\"It should be => lambda_l1_range[0]<lambda_l1_range[1]\")\n","    options = np.random.uniform(low=lambda_l1_range[0], high=lambda_l1_range[1], size=size)\n","    for i, para in enumerate(options):\n","      logger.info(f\"\\n L1 Trail:{i+1} - Model is getting trained with L1 regularisation parameter {para}\\n\")\n","      model =  Net().to(device)\n","      optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","      scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n","      temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch = best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer, lambda_l1=para, lambda_l2=0, scheduler=scheduler)\n","    (best_para_train_acc, best_para_test_acc), idx = get_best_train_test_acc(temp_best_train_acc_list, temp_best_test_acc_list)\n","    idx -= 1\n","    final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = all_lambdal1_train_test_acc_from_best_epoch[idx]\n","    logger.info(f\"\\n===================> final_best_train_acc: {final_best_train_acc}, final_best_test_acc: {final_best_test_acc}, final_best_lambda_l1: {final_best_lambda_l1} <===================\\n\")\n","    return final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2\n","\n","  elif lambda_l2_range:\n","    if lambda_l2_range[0]>lambda_l2_range[1]:\n","      raise Exception(\"It should be => lambda_l2_range[0]<lambda_l2_range[1]\")\n","    options = np.random.uniform(low=lambda_l2_range[0], high=lambda_l2_range[1], size=size)\n","    for i, para in enumerate(options):\n","      logger.info(f\"\\n L2 Trail:{i+1} - Model is getting trained with L2 regularisation parameter {para}\\n\")\n","      model =  Net().to(device)\n","      optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=para)\n","      scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n","      temp_best_train_acc_list, temp_best_test_acc_list, all_lambdal1_train_test_acc_from_best_epoch = best_tr_te_acc_from_epoch(epochs, model, device, train_loader, test_loader, optimizer=optimizer, lambda_l1=0, lambda_l2=para, scheduler=scheduler)\n","    (best_para_train_acc, best_para_test_acc), idx = get_best_train_test_acc(temp_best_train_acc_list, temp_best_test_acc_list)\n","    idx -= 1\n","    final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = all_lambdal1_train_test_acc_from_best_epoch[idx]\n","    logger.info(f\"\\n===================> final_best_train_acc: {final_best_train_acc}, final_best_test_acc: {final_best_test_acc}, final_best_lambda_l2: {final_best_lambda_l2} <===================\\n\")\n","    return final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2\n","\n","  else:\n","    raise Exception(\"Select at least one parameter to search its mathematical space\")\n"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMCFxeAKOB53","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":451},"outputId":"2a98bf32-3c9c-4d83-993d-2dfe6f80e08b"},"source":["model =  Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n","EPOCHS = 15\n","scheduler = StepLR(optimizer, step_size=12, gamma=0.2)\n","# lambda_l1=0\n","l1_l2_trails=50\n","\n","# para_grid_lambda = [[0,0.1],[0,0.01],[0,0.001],[0,0.0001]]\n","para_grid_lambda = [[0,0.0001], [0,0.001], [0,0.01],[0,0.1]]\n","# para_grid_lambda = [[0,0.0001], [0,0.1]]\n","results_lambda_l1 = []\n","results_lambda_l2 = []\n","results_lambda_l1_l2 = []\n","size = 20 # Number of random choices in the given range\n","\n","\n","# ## L1 regularisation hyper parameter search\n","\n","# for para_range in para_grid_lambda:\n","#   logger.info(f\"\\n===================> Started - Trail on L1 reg parameters range - {para_range}, Number of trails - {size}, Number of Epochs - {EPOCHS} <===================\\n\")\n","#   final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = my_grid_search(EPOCHS, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = para_range, lambda_l2_range = [], size = size)\n","#   results_lambda_l1.append((final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2))\n","#   logger.info(f\"\\n===================> current results_lambda_l1 - {results_lambda_l1} <===================\\n\")\n","#   logger.info(f\"\\n===================> Completed - Trail on L1 reg parameters range - {para_range} <===================\\n\")\n","\n","# logger.info(f\"\\n===================> L1 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda}<===================\\n\")\n","# for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l1:\n","#   logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")\n","\n","# ## L2 regularisation hyper parameter search\n","\n","# for para_range in para_grid_lambda:\n","#   logger.info(f\"\\n===================> Started - Trail on L2 reg parameters range - {para_range}, Number of trails - {size}, Number of Epochs - {EPOCHS}<===================\\n\")\n","#   final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = my_grid_search(EPOCHS, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = [], lambda_l2_range = para_range, size = size)\n","#   results_lambda_l2.append((final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2))\n","#   logger.info(f\"\\n===================> current results_lambda_l2 - {results_lambda_l2} <===================\\n\")\n","#   logger.info(f\"\\n===================> Completed - Trail on L2 reg parameters range - {para_range} <===================\\n\")\n","\n","# logger.info(f\"\\n===================> L2 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda}<===================\\n\")\n","# for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l2:\n","#   logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")\n","\n","## L1&L2 regularisation hyper parameter search\n","\n","# l1 and l2 reg paras in same range given but can be given different ranges by writing little more sophisticated logic\n","for para_range in para_grid_lambda:\n","  logger.info(f\"\\n===================> Started - Trail on L1 & L2 reg parameters range - {para_range}, Number of para_ranges - {size}, , Number of trails per para_range - {l1_l2_trails}, Number of Epochs - {EPOCHS}<===================\\n\")\n","  final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 = my_grid_search(EPOCHS, model, device, train_loader, test_loader, optimizer, scheduler, lambda_l1_range = para_range, lambda_l2_range = para_range, size = size, l1_l2_trails=l1_l2_trails)\n","  results_lambda_l1_l2.append((final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2))\n","  logger.info(f\"\\n===================> current results_lambda_l1_l2 - {results_lambda_l1_l2} <===================\\n\")\n","  logger.info(f\"\\n===================> Completed - Trail on L1 and L2 reg parameters range - {para_range} <===================\\n\")\n","\n","logger.info(f\"\\n===================> L1 & L2 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda} <===================\\n\")\n","for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l1_l2:\n","  logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loss=0.1445353627204895 Batch_id=468 Current_train_batch_accuracy=93.64: 100%|██████████| 469/469 [00:17<00:00, 27.19it/s]\n","Loss=0.11320868134498596 Batch_id=468 Current_train_batch_accuracy=97.81: 100%|██████████| 469/469 [00:17<00:00, 27.09it/s]\n","Loss=0.11690933257341385 Batch_id=468 Current_train_batch_accuracy=98.04: 100%|██████████| 469/469 [00:17<00:00, 27.20it/s]\n","Loss=0.11598369479179382 Batch_id=468 Current_train_batch_accuracy=98.17: 100%|██████████| 469/469 [00:17<00:00, 27.19it/s]\n","Loss=0.14078304171562195 Batch_id=468 Current_train_batch_accuracy=98.36: 100%|██████████| 469/469 [00:17<00:00, 26.95it/s]\n","Loss=0.11441995203495026 Batch_id=468 Current_train_batch_accuracy=98.33: 100%|██████████| 469/469 [00:17<00:00, 26.79it/s]\n","Loss=0.13979387283325195 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:17<00:00, 27.02it/s]\n","Loss=0.088969886302948 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:17<00:00, 26.86it/s]\n","Loss=0.08585639297962189 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:17<00:00, 26.89it/s]\n","Loss=0.10977882146835327 Batch_id=468 Current_train_batch_accuracy=98.48: 100%|██████████| 469/469 [00:17<00:00, 27.18it/s]\n","Loss=0.10809442400932312 Batch_id=468 Current_train_batch_accuracy=98.59: 100%|██████████| 469/469 [00:17<00:00, 26.84it/s]\n","Loss=0.14330336451530457 Batch_id=468 Current_train_batch_accuracy=98.57: 100%|██████████| 469/469 [00:17<00:00, 27.16it/s]\n","Loss=0.07816740870475769 Batch_id=468 Current_train_batch_accuracy=99.02: 100%|██████████| 469/469 [00:17<00:00, 26.60it/s]\n","Loss=0.13448546826839447 Batch_id=468 Current_train_batch_accuracy=99.08: 100%|██████████| 469/469 [00:17<00:00, 27.07it/s]\n","Loss=0.07112370431423187 Batch_id=468 Current_train_batch_accuracy=99.12: 100%|██████████| 469/469 [00:17<00:00, 27.07it/s]\n","Loss=0.1745215356349945 Batch_id=468 Current_train_batch_accuracy=93.20: 100%|██████████| 469/469 [00:17<00:00, 26.90it/s]\n","Loss=0.12241372466087341 Batch_id=468 Current_train_batch_accuracy=97.72: 100%|██████████| 469/469 [00:17<00:00, 27.36it/s]\n","Loss=0.11540554463863373 Batch_id=468 Current_train_batch_accuracy=98.09: 100%|██████████| 469/469 [00:17<00:00, 27.37it/s]\n","Loss=0.09106899052858353 Batch_id=468 Current_train_batch_accuracy=98.29: 100%|██████████| 469/469 [00:17<00:00, 27.01it/s]\n","Loss=0.08711433410644531 Batch_id=468 Current_train_batch_accuracy=98.39: 100%|██████████| 469/469 [00:17<00:00, 27.38it/s]\n","Loss=0.06879529356956482 Batch_id=468 Current_train_batch_accuracy=98.54: 100%|██████████| 469/469 [00:17<00:00, 27.24it/s]\n","Loss=0.14118459820747375 Batch_id=468 Current_train_batch_accuracy=98.50: 100%|██████████| 469/469 [00:17<00:00, 27.32it/s]\n","Loss=0.0969211608171463 Batch_id=468 Current_train_batch_accuracy=98.58: 100%|██████████| 469/469 [00:17<00:00, 26.71it/s]\n","Loss=0.0782104879617691 Batch_id=468 Current_train_batch_accuracy=98.66: 100%|██████████| 469/469 [00:17<00:00, 26.91it/s]\n","Loss=0.07253333926200867 Batch_id=468 Current_train_batch_accuracy=98.67: 100%|██████████| 469/469 [00:17<00:00, 27.11it/s]\n","Loss=0.051787279546260834 Batch_id=468 Current_train_batch_accuracy=98.68: 100%|██████████| 469/469 [00:17<00:00, 26.62it/s]\n","Loss=0.0758800059556961 Batch_id=468 Current_train_batch_accuracy=98.72: 100%|██████████| 469/469 [00:16<00:00, 27.82it/s]\n","Loss=0.07494263350963593 Batch_id=468 Current_train_batch_accuracy=99.12: 100%|██████████| 469/469 [00:16<00:00, 27.97it/s]\n","Loss=0.0747246965765953 Batch_id=468 Current_train_batch_accuracy=99.19: 100%|██████████| 469/469 [00:17<00:00, 26.99it/s]\n","Loss=0.08306131511926651 Batch_id=468 Current_train_batch_accuracy=99.21: 100%|██████████| 469/469 [00:17<00:00, 27.46it/s]\n","Loss=0.16465595364570618 Batch_id=468 Current_train_batch_accuracy=93.88: 100%|██████████| 469/469 [00:17<00:00, 27.57it/s]\n","Loss=0.12407925724983215 Batch_id=468 Current_train_batch_accuracy=97.66: 100%|██████████| 469/469 [00:17<00:00, 27.41it/s]\n","Loss=0.20929595828056335 Batch_id=468 Current_train_batch_accuracy=97.97: 100%|██████████| 469/469 [00:17<00:00, 26.93it/s]\n","Loss=0.15274685621261597 Batch_id=468 Current_train_batch_accuracy=98.21: 100%|██████████| 469/469 [00:17<00:00, 27.07it/s]\n","Loss=0.10638916492462158 Batch_id=468 Current_train_batch_accuracy=98.31: 100%|██████████| 469/469 [00:17<00:00, 27.15it/s]\n","Loss=0.11444522440433502 Batch_id=468 Current_train_batch_accuracy=98.43: 100%|██████████| 469/469 [00:17<00:00, 26.87it/s]\n","Loss=0.09477374702692032 Batch_id=468 Current_train_batch_accuracy=98.43: 100%|██████████| 469/469 [00:17<00:00, 27.42it/s]\n","Loss=0.08171804994344711 Batch_id=468 Current_train_batch_accuracy=98.53: 100%|██████████| 469/469 [00:17<00:00, 26.63it/s]\n","Loss=0.17825986444950104 Batch_id=468 Current_train_batch_accuracy=98.54: 100%|██████████| 469/469 [00:17<00:00, 26.73it/s]\n","Loss=0.09688888490200043 Batch_id=468 Current_train_batch_accuracy=98.51: 100%|██████████| 469/469 [00:17<00:00, 27.57it/s]\n","Loss=0.1261799931526184 Batch_id=468 Current_train_batch_accuracy=98.56: 100%|██████████| 469/469 [00:17<00:00, 26.88it/s]\n","Loss=0.08506771922111511 Batch_id=468 Current_train_batch_accuracy=98.53: 100%|██████████| 469/469 [00:17<00:00, 27.06it/s]\n","Loss=0.10189619660377502 Batch_id=468 Current_train_batch_accuracy=99.05: 100%|██████████| 469/469 [00:17<00:00, 27.03it/s]\n","Loss=0.07521842420101166 Batch_id=468 Current_train_batch_accuracy=99.14: 100%|██████████| 469/469 [00:17<00:00, 26.78it/s]\n","Loss=0.07155755907297134 Batch_id=468 Current_train_batch_accuracy=99.18: 100%|██████████| 469/469 [00:17<00:00, 26.90it/s]\n","Loss=0.22064781188964844 Batch_id=468 Current_train_batch_accuracy=93.55: 100%|██████████| 469/469 [00:17<00:00, 27.32it/s]\n","Loss=0.16765005886554718 Batch_id=468 Current_train_batch_accuracy=97.64: 100%|██████████| 469/469 [00:17<00:00, 26.93it/s]\n","Loss=0.1436578929424286 Batch_id=468 Current_train_batch_accuracy=97.95: 100%|██████████| 469/469 [00:17<00:00, 27.27it/s]\n","Loss=0.10191348195075989 Batch_id=468 Current_train_batch_accuracy=98.04: 100%|██████████| 469/469 [00:17<00:00, 26.90it/s]\n","Loss=0.08778740465641022 Batch_id=468 Current_train_batch_accuracy=98.27: 100%|██████████| 469/469 [00:17<00:00, 27.07it/s]\n","Loss=0.1646878570318222 Batch_id=468 Current_train_batch_accuracy=98.34: 100%|██████████| 469/469 [00:17<00:00, 27.23it/s]\n","Loss=0.10788773000240326 Batch_id=468 Current_train_batch_accuracy=98.39: 100%|██████████| 469/469 [00:16<00:00, 27.64it/s]\n","Loss=0.1058434396982193 Batch_id=468 Current_train_batch_accuracy=98.49: 100%|██████████| 469/469 [00:17<00:00, 27.22it/s]\n","Loss=0.15698128938674927 Batch_id=468 Current_train_batch_accuracy=98.48: 100%|██████████| 469/469 [00:17<00:00, 27.30it/s]\n","Loss=0.12022046744823456 Batch_id=468 Current_train_batch_accuracy=98.56: 100%|██████████| 469/469 [00:17<00:00, 27.33it/s]\n","Loss=0.12947535514831543 Batch_id=468 Current_train_batch_accuracy=98.53: 100%|██████████| 469/469 [00:17<00:00, 26.95it/s]\n","Loss=0.15482592582702637 Batch_id=468 Current_train_batch_accuracy=98.57: 100%|██████████| 469/469 [00:17<00:00, 27.26it/s]\n","Loss=0.07206542789936066 Batch_id=468 Current_train_batch_accuracy=99.03: 100%|██████████| 469/469 [00:17<00:00, 27.14it/s]\n","Loss=0.14235305786132812 Batch_id=468 Current_train_batch_accuracy=99.12: 100%|██████████| 469/469 [00:17<00:00, 27.47it/s]\n","Loss=0.081979900598526 Batch_id=468 Current_train_batch_accuracy=99.20: 100%|██████████| 469/469 [00:17<00:00, 27.12it/s]\n","Loss=0.14509683847427368 Batch_id=468 Current_train_batch_accuracy=92.90: 100%|██████████| 469/469 [00:17<00:00, 27.10it/s]\n","Loss=0.13542534410953522 Batch_id=468 Current_train_batch_accuracy=97.64: 100%|██████████| 469/469 [00:17<00:00, 27.35it/s]\n","Loss=0.2212260663509369 Batch_id=468 Current_train_batch_accuracy=97.92: 100%|██████████| 469/469 [00:17<00:00, 27.27it/s]\n","Loss=0.1082998663187027 Batch_id=468 Current_train_batch_accuracy=98.19: 100%|██████████| 469/469 [00:16<00:00, 27.82it/s]\n","Loss=0.19272032380104065 Batch_id=468 Current_train_batch_accuracy=98.30: 100%|██████████| 469/469 [00:17<00:00, 26.87it/s]\n","Loss=0.14064808189868927 Batch_id=468 Current_train_batch_accuracy=98.42: 100%|██████████| 469/469 [00:17<00:00, 27.27it/s]\n","Loss=0.10392129421234131 Batch_id=468 Current_train_batch_accuracy=98.31: 100%|██████████| 469/469 [00:17<00:00, 26.85it/s]\n","Loss=0.092403344810009 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:17<00:00, 27.07it/s]\n","Loss=0.07895700633525848 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:16<00:00, 27.69it/s]\n","Loss=0.12969011068344116 Batch_id=468 Current_train_batch_accuracy=98.55: 100%|██████████| 469/469 [00:17<00:00, 27.15it/s]\n","Loss=0.0868312418460846 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:17<00:00, 27.48it/s]\n","Loss=0.07694876194000244 Batch_id=468 Current_train_batch_accuracy=98.48: 100%|██████████| 469/469 [00:17<00:00, 27.15it/s]\n","Loss=0.08015448600053787 Batch_id=468 Current_train_batch_accuracy=99.03: 100%|██████████| 469/469 [00:17<00:00, 27.38it/s]\n","Loss=0.05700363963842392 Batch_id=468 Current_train_batch_accuracy=99.08: 100%|██████████| 469/469 [00:17<00:00, 26.99it/s]\n","Loss=0.0778498500585556 Batch_id=468 Current_train_batch_accuracy=99.14: 100%|██████████| 469/469 [00:17<00:00, 26.53it/s]\n","Loss=0.20110340416431427 Batch_id=468 Current_train_batch_accuracy=93.86: 100%|██████████| 469/469 [00:17<00:00, 27.03it/s]\n","Loss=0.1199677586555481 Batch_id=468 Current_train_batch_accuracy=97.69: 100%|██████████| 469/469 [00:16<00:00, 27.60it/s]\n","Loss=0.1123884916305542 Batch_id=468 Current_train_batch_accuracy=98.03: 100%|██████████| 469/469 [00:17<00:00, 27.17it/s]\n","Loss=0.11135786771774292 Batch_id=468 Current_train_batch_accuracy=98.23: 100%|██████████| 469/469 [00:16<00:00, 27.70it/s]\n","Loss=0.13574565947055817 Batch_id=468 Current_train_batch_accuracy=98.34: 100%|██████████| 469/469 [00:17<00:00, 27.01it/s]\n","Loss=0.15925125777721405 Batch_id=468 Current_train_batch_accuracy=98.33: 100%|██████████| 469/469 [00:17<00:00, 27.02it/s]\n","Loss=0.1835230588912964 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:17<00:00, 27.55it/s]\n","Loss=0.10887669026851654 Batch_id=468 Current_train_batch_accuracy=98.47: 100%|██████████| 469/469 [00:17<00:00, 26.88it/s]\n","Loss=0.13847440481185913 Batch_id=468 Current_train_batch_accuracy=98.50: 100%|██████████| 469/469 [00:17<00:00, 26.80it/s]\n","Loss=0.14588876068592072 Batch_id=468 Current_train_batch_accuracy=98.49: 100%|██████████| 469/469 [00:17<00:00, 27.36it/s]\n","Loss=0.15709859132766724 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:17<00:00, 27.34it/s]\n","Loss=0.09044524282217026 Batch_id=468 Current_train_batch_accuracy=98.44: 100%|██████████| 469/469 [00:17<00:00, 26.75it/s]\n","Loss=0.10726617276668549 Batch_id=468 Current_train_batch_accuracy=99.06: 100%|██████████| 469/469 [00:17<00:00, 26.35it/s]\n","Loss=0.056948572397232056 Batch_id=468 Current_train_batch_accuracy=99.15: 100%|██████████| 469/469 [00:16<00:00, 27.60it/s]\n","Loss=0.06381035596132278 Batch_id=468 Current_train_batch_accuracy=99.14: 100%|██████████| 469/469 [00:17<00:00, 27.18it/s]\n","Loss=0.10960406064987183 Batch_id=468 Current_train_batch_accuracy=93.12: 100%|██████████| 469/469 [00:17<00:00, 27.15it/s]\n","Loss=0.10820502787828445 Batch_id=468 Current_train_batch_accuracy=97.86: 100%|██████████| 469/469 [00:17<00:00, 26.91it/s]\n","Loss=0.07923999428749084 Batch_id=468 Current_train_batch_accuracy=98.09: 100%|██████████| 469/469 [00:17<00:00, 27.12it/s]\n","Loss=0.13694623112678528 Batch_id=468 Current_train_batch_accuracy=98.31: 100%|██████████| 469/469 [00:17<00:00, 27.34it/s]\n","Loss=0.0779259204864502 Batch_id=468 Current_train_batch_accuracy=98.46: 100%|██████████| 469/469 [00:17<00:00, 26.93it/s]\n","Loss=0.06898527592420578 Batch_id=468 Current_train_batch_accuracy=98.49: 100%|██████████| 469/469 [00:17<00:00, 27.19it/s]\n","Loss=0.11198799312114716 Batch_id=468 Current_train_batch_accuracy=98.61: 100%|██████████| 469/469 [00:17<00:00, 27.13it/s]\n","Loss=0.1370599865913391 Batch_id=468 Current_train_batch_accuracy=98.62: 100%|██████████| 469/469 [00:17<00:00, 27.38it/s]\n","Loss=0.047888897359371185 Batch_id=468 Current_train_batch_accuracy=98.76: 100%|██████████| 469/469 [00:17<00:00, 27.41it/s]\n","Loss=0.05849872902035713 Batch_id=468 Current_train_batch_accuracy=98.80: 100%|██████████| 469/469 [00:17<00:00, 27.30it/s]\n","Loss=0.06216133385896683 Batch_id=468 Current_train_batch_accuracy=98.80: 100%|██████████| 469/469 [00:17<00:00, 27.39it/s]\n","Loss=0.060567185282707214 Batch_id=468 Current_train_batch_accuracy=98.85: 100%|██████████| 469/469 [00:17<00:00, 27.32it/s]\n","Loss=0.06910418719053268 Batch_id=468 Current_train_batch_accuracy=99.13: 100%|██████████| 469/469 [00:17<00:00, 26.93it/s]\n","Loss=0.03735818713903427 Batch_id=468 Current_train_batch_accuracy=99.20: 100%|██████████| 469/469 [00:17<00:00, 27.39it/s]\n","Loss=0.03544967621564865 Batch_id=468 Current_train_batch_accuracy=99.30: 100%|██████████| 469/469 [00:17<00:00, 27.51it/s]\n","Loss=0.1916750967502594 Batch_id=468 Current_train_batch_accuracy=94.09: 100%|██████████| 469/469 [00:17<00:00, 27.04it/s]\n","Loss=0.10313642024993896 Batch_id=468 Current_train_batch_accuracy=97.93: 100%|██████████| 469/469 [00:17<00:00, 26.90it/s]\n","Loss=0.06995946913957596 Batch_id=468 Current_train_batch_accuracy=98.11: 100%|██████████| 469/469 [00:17<00:00, 27.29it/s]\n","Loss=0.05924854427576065 Batch_id=468 Current_train_batch_accuracy=98.44: 100%|██████████| 469/469 [00:17<00:00, 27.34it/s]\n","Loss=0.10324756801128387 Batch_id=427 Current_train_batch_accuracy=98.57:  91%|█████████ | 426/469 [00:15<00:01, 26.74it/s] "],"name":"stderr"},{"output_type":"stream","text":["Buffered data was truncated after reaching the output size limit."],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ojw9VJdwISTh","colab_type":"code","colab":{}},"source":["# save_model(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mrwcQ7TBjYen","colab_type":"code","colab":{}},"source":["# ## Load the model\n","# model_test = Net().to(device)\n","# PATH='./test_model.pickle'\n","# model_test.load_state_dict(torch.load(PATH))\n","# test(model_test, device, test_loader)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"87RaqGSEOWDe","colab_type":"code","colab":{}},"source":["# fig, axs = plt.subplots(2,2,figsize=(15,10))\n","# axs[0, 0].plot(train_losses)\n","# axs[0, 0].set_title(\"Training Loss\")\n","# axs[1, 0].plot(train_acc)\n","# axs[1, 0].set_title(\"Training Accuracy\")\n","# axs[0, 1].plot(test_losses)\n","# axs[0, 1].set_title(\"Test Loss\")\n","# axs[1, 1].plot(test_acc)\n","# axs[1, 1].set_title(\"Test Accuracy\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4gtYupNvG5Yb","colab_type":"code","colab":{}},"source":["# # function boundaries\n","# xmin, xmax, xstep = -4.5, 4.5, .9\n","# ymin, ymax, ystep = -4.5, 4.5, .9\n","\n","\n","# # Let's create some points\n","# x1, y1 = np.meshgrid(np.arange(xmin, xmax + xstep, xstep), np.arange(ymin, ymax + ystep, ystep))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bcWB1LRH8ADK","colab_type":"code","colab":{}},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUd3qZ7777Pm","colab_type":"code","colab":{}},"source":["np.mean(np.random.uniform(low=0.0, high=10.0, size=20))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nF3wxOEX8Ezr","colab_type":"code","colab":{}},"source":["logger.info(f\"\\n===================> L1 - Results of Coarse/finer grid search in various ranges - {para_grid_lambda}<===================\\n\")\n","for final_best_train_acc, final_best_test_acc, final_best_lambda_l1, final_best_lambda_l2 in results_lambda_l1:\n","  logger.info(f\"L1 reg parameter: {final_best_lambda_l1}, L2 reg parameter: {final_best_lambda_l2}, Train_acc: {final_best_train_acc}, Test_acc: {final_best_test_acc}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vkiEVmjdvvM1","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}